matΣτο παρόν κεφάλαιο γίνεται μια εξερεύνηση στους αλγορίθμους επιβλεπόμενης μάθησης. Αυτό επιτεύχθηκε με τη χρήση γραμμικών και μη-γραμμικών ταξινομητών διερευνώντας διαφορετικά δεδομένα εισόδου για κάθε περίπτωση. Η βιβλιοθήκη που χρησιμοποιήθηκε για τη γραμμική ταξινόμηση ονομάζεται \en{LIBLINEAR} και χαρακτηρίζεται με εξαιρετικές επιδόσεις σε προβλήματα με μεγάλα σετ δεδομένων. Αντίστοιχα για τη μη-γραμμική ταξινόμηση χρησιμοποιήθηκε η βιβλιοθήκη \en{LIBSVM}, η οποία αναγάγει τα δεδομένα εισόδου σε μεγαλύτερο χώρο διαστάσεων.
\section{Θεωρία γραμμικής ταξινόμησης}
Η βιβλιοθήκη \en{LIBLINEAR} υποστηρίζει δύο δημοφιλείς δυαδικά γραμμικούς ταξινομητές: τη λογιστική παλινδρόμηση (\en{Logistic Regression}) και τη γραμμική μηχανή υποστήριξης διανυσμάτων (\en{linear SVM}). Δεδομένου ενός σετ εκπαίδευσης $(\mathbf{x}_i, y_i)$, $i=1,...,l$, όπου $\mathbf{x}_i\in\R^n$ είναι ένα χαρακτηριστικό διάνυσμα και $y_i=\pm1$ είναι οι ετικέτες, ένας γραμμικός ταξινομητής βρίσκει ένα διάνυσμα βαρών $\mathbf{w}\in\R^n$ επιλύοντας το ακόλουθο πρόβλημα:
\begin{center}
$min_{\mathbf{w}}f(\mathbf{w})\equiv\frac{1}{2}\mathbf{w}^T\mathbf{w}+C\sum_{i=1}^{l}\xi(y_i\mathbf{w}^T x_i)$
\end{center}
όπου $\mathbf{w}^T\mathbf{w}/2$ είναι ο όρος ομαλοποίησης, $\xi(y_i\mathbf{w}^T x_i)$ είναι η συνάρτηση κόστους (\en{loss function}) και $C>0$ είναι η παράμετρος ομαλοποίησης. Θεωρούμε τις συναρτήσεις κόστους στη λογιστική παλινδρόμηση (\en{LR}), στο  \en{L1-SVM}, στο \en{L2-SVM}:
\begin{center}
$\xi_{LR}(y\mathbf{w}^T\mathbf{x})=log(1 + exp(-y\mathbf{w}^T\mathbf{x}))$\\
$\xi_{L1}(y\mathbf{w}^T\mathbf{x})=(max(0, 1 - y\mathbf{w}^T\mathbf{x}))$\\
$\xi_{L2}(y\mathbf{w}^T\mathbf{x})=(max(0, 1 - y\mathbf{w}^T\mathbf{x}))^2$
\end{center}
Σε μερικές περιπτώσεις, η συνάρτηση διακρίσεως του ταξινομητή περιλαμβάνει και ένα παράγοντα βάρους, $b$. Η \en{LIBLINEAR} χειρίζεται αυτό τον παράγοντα αυξάνοντας το διάνυσμα $\mathbf{w}$ και κάθε παράδειγμα $\mathbf{x}_i$ με μία επιπλέον διάσταση: $\mathbf{w}^T \leftarrow [\mathbf{w}^T, b]$, $\mathbf{x}_i^T \leftarrow [\mathbf{x}_i^T, B]$, όπου B είναι μια σταθερά που ορίζεται από το χρήστη. Η προσέγγιση για το \en{L1-SVM} και το  \en{L2-SVM} είναι μέσω της μεθόδου \en{coordinate descent}. Για το \en{LR} και το \en{L2-SVM}, η \en{LIBLINEAR} υλοποιεί μια μέθοδο περιοχής εμπιστοσύνης \en{Newton}. Στη φάση των δοκιμών, εκτιμάται ένα μέλος των δεδομένων $\mathbf{x}$ σαν θετικό εάν $\mathbf{w}^T\mathbf{x}>0$, και αρνητικό σε αντίθετη περίπτωση\cite{liblinearguide} \cite{liblinearreport}.\par
Η μηχανή διανυσμάτων υποστήριξης εντάσσεται στο γενικότερο πλαίσιο της βελτιστοποίησης κυρτών συναρτήσεων και έχει νόημα η προσέγγισή της για όλους τους γραμμικούς ταξινομητές. Σε αδρές γραμμές, η διαδικασία εξελίσσεται σε τέσσερα κύρια βήματα:
\begin{itemize}
\item Το πρόβλημα της εύρεσης του βελτίστου υπερεπιπέδου ξεκινά με μια δήλωση του προβλήματος στον πρωτεύοντα χώρο βαρών, ως ένα πρόβλημα βελτιστοποίησης με περιορισμούς.
\item Κατασκευάζεται η συνάρτηση \en{Lagrange} του προβλήματος.
\item Διατυπώνονται οι συνθήκες για τη βελτιστοποίηση της μηχανής.
\item Στήνεται το σκηνικό για την επίλυση του προβλήματος βελτιστοποίησης στο δυικό χώρο των πολλαπλασιαστών \en{Lagrange}.
\end{itemize}
Όπως προαναφέρθηκε, το πρωτεύον πρόβλημα ασχολείται με μια κυρτή συνάρτηση κόστους και γραμμικούς περιορισμούς. Δοθέντος ενός τέτοιου προβλήματος βελτιστοποίησης με περιορισμούς, είναι δυνατό να κατασκευάσουμε ένα άλλο πρόβλημα, το αποκαλούμενο δυικό του πρωτεύοντος. Αυτό το δεύτερο πρόβλημα έχει την ίδια βέλτιστη τιμή με το πρωτεύον πρόβλημα, αλλά με τους πολλαπλασιαστές \en{Lagrange} να παρέχουν τη βέλτιστη λύση\cite{haykin}.
\section{Εξερεύνηση γραμμικών ταξινομητών}
Αρχικά έγινε μια εξερεύνηση των μεθόδων που παρέχει η \en{LIBLINEAR} για την επίλυση του δυαδικού προβλήματος. Λαμβάνοντας υπόψη 2.000 καταναλώσεις πελατών με ωριαίες μετρήσεις, επιλέχθηκε 10\% ποσοστό ρευματοκλοπών για την προσομοίωση. Η βιβλιοθήκη που χρησιμοποιήθηκε περιλαμβάνει 7 διαφορετικούς συνδυασμούς ταξινομητών και συναρτήσεων κόστους για να μπορούν όσο το δυνατόν περισσότερα προβλήματα. Παρόλα αυτά οι μέθοδοι \en{L1} είναι παλαιότερες εκδόσεις των \en{L2} και αναμένεται να έχουν χειρότερα αποτελέσματα στις δοκιμές. Για την σφαιρική αντιμετώπιση του προβλήματος χρησιμοποιήθηκαν όλοι οι ταξινομητές που παρέχονται από τη βιβλιοθήκη σε κάθε τύπο απάτης. Παρακάτω παραθέτονται οι συνδυασμοί ταξινομητών και συναρτήσεων κόστους που δοκιμάστηκαν και τα αποτελέσματα σε κάθε τύπο απάτης.
\begin{enumerate}
\item \en{L2} ομαλοποιημένη λογιστική παλινδρόμηση (πρωτεύον)
\item \en{L2} oμαλοποιημένος ταξινομητής με \en{L2} συνάρτηση κόστους διανυσμάτων υποστήριξης (δυικό)
\item \en{L2} oμαλοποιημένος ταξινομητής με \en{L2} συνάρτηση κόστους διανυσμάτων υποστήριξης (πρωτεύον)
\item \en{L2} oμαλοποιημένη ταξινομητής με \en{L1} συνάρτηση κόστους διανυσμάτων υποστήριξης (δυικό)
\item Ταξινόμηση διανυσμάτων υποστήριξης από \en{Crammer} και \en{Singer}
\item \en{L1} oμαλοποιημένος ταξινομητής με \en{L2} συνάρτηση κόστους διανυσμάτων υποστήριξης
\item \en{L1} ομαλοποιημένη λογιστική παλινδρόμηση
\item \en{L2} ομαλοποιημένη λογιστική παλινδρόμηση (δυικό)
\end{enumerate}
Παρατηρώντας τους πίνακες αποτελεσμάτων εύκολα αποδεικνύεται η αρχική υπόθεση πως οι ταξινομητές και συναρτήσεις κόστους L2 έχουν καλύτερη συμπεριφορά ως προς την αντιμετώπιση του προβλήματος αναγνώρισης χρονοσειρών.  Πιο συγκεκριμένα για την τελική επιλογή του συνδυασμού μεθόδων υπολογίστηκε μέσος όρος των δοκιμών με γνώμονα το καλύτερο \en{F1 score}, καθώς είναι μια αρκετά ζυγισμένη μετρική για τα προβλήματα ταξινόμησης. Βάση λοιπόν του Πίνακα \ref{tab:meanF1test} την καλύτερη επίδοση έχει το πρωτεύον πρόβλημα που αποτελείται από \en{L2} oμαλοποιημένο ταξινομητή με \en{L2} συνάρτηση κόστους διανυσμάτων υποστήριξης.

\begin{table}[ht!]
\centering
\begin{tabular}{ |c||c|c|c|c|c|c|c|c|  }
 \hline
 Συνδυασμός & 1 & 2 & 3 & 4 & 5 & 6 & 7& 8 \\
 \hline
\en{F1 score} & 94.91 & 94.80 & 95.39 &  95.01 & 94.84& 91.87 &88.97& 94.91\\
  \hline
\end{tabular}
\caption{Μέσος όρος \en{F1 score} των δοκιμών}
\label{tab:meanF1test}
\end{table}


\begin{table}[ht!]
\centering
\begin{tabular}{ |c||c|c|c|c|c|  }
 \hline
 Συνδυασμός & \en{DR}  & \en{FPR} & \en{Accuracy} & \en{F1 score} & \en{BDR} \\
 \hline
1 & 98.48 & 0.19 & 99.67 & 98.48 & 0.98\\
  \hline
2 & 98.48 & 0.19 & 99.67 & 98.48 & 0.98\\
  \hline
3 & 98.48 & 0.19 & 99.67 & 98.48 & 0.98\\
  \hline
4 & 98.48 & 0.19 & 99.67 & 98.48 & 0.98\\
  \hline
5 & 96.97 & 0.00 & 99.67 & 98.46 & 1.00\\
 \hline
6 & 96.97 & 0.37 & 99.33 & 96.97 & 0.97\\
 \hline
7 & 95.45 & 0.56 & 99.00 & 95.45 & 0.95\\
 \hline
8 & 98.48 & 0.19 & 99.67 & 98.48 & 0.98\\
 \hline
\end{tabular}
\caption{Αποτελέσματα δοκιμής τύπου 1}
\label{tab:exploreclassifiers1}
\end{table}

\begin{table}
\centering
\begin{tabular}{ |c||c|c|c|c|c|  }
 \hline
 Συνδυασμός & \en{DR}  & \en{FPR} & \en{Accuracy} & \en{F1 score} & \en{BDR} \\
 \hline
1 & 91.53 & 0.00 & 99.17 & 95.58 & 1.00\\
  \hline
2 & 89.83 & 0.18 & 98.83 & 93.81 & 0.98 \\
  \hline
3 & 91.53 & 0.37 & 98.83 & 93.91 & 0.96\\
  \hline
4 & 89.83 & 0.18 & 98.83 & 93.81 & 0.98\\
  \hline
5 & 84.75 & 0.00 & 98.50 & 91.74 & 1.00\\
 \hline
6 & 86.44 & 0.37 & 98.33 & 91.07 & 0.96\\
 \hline
7 & 81.36 & 0.74 & 97.50 & 86.49 & 0.92\\
 \hline
8 & 91.53 & 0.00 & 99.17 & 95.58 & 1.00\\
 \hline
\end{tabular}
\caption{Αποτελέσματα δοκιμής τύπου 2}
\label{tab:exploreclassifiers2}
\end{table}

\begin{table}
\centering
\begin{tabular}{ |c||c|c|c|c|c|  }
 \hline
 Συνδυασμός & \en{DR}  & \en{FPR} & \en{Accuracy} & \en{F1 score} & \en{BDR} \\
 \hline
 1 & 93.85 & 0.75 & 98.67 & 93.85 & 0.93\\
  \hline
 2 & 92.31 & 0.37 & 98.83 & 94.49 & 0.96\\
  \hline
 3 & 92.31 & 0.37 & 98.83 & 94.49 & 0.96\\
  \hline
 4 & 93.85 & 0.37 & 99.00 & 95.31 & 0.97\\
  \hline
 5 & 93.85 & 0.37 & 99.00 & 95.31 & 0.97\\
 \hline
 6 & 92.31 & 0.75 & 98.50 & 93.02 & 0.93\\
 \hline
7& 83.08 & 0.93 & 97.33 & 87.10 & 0.91\\
 \hline
8 & 93.85 & 0.75 & 98.67 & 93.85 & 0.93\\
 \hline
\end{tabular}
\caption{Αποτελέσματα δοκιμής τύπου 3}
\label{tab:exploreclassifiers3}
\end{table}

\begin{table}
\centering
\begin{tabular}{ |c||c|c|c|c|c|  }
 \hline
 Συνδυασμός & \en{DR}  & \en{FPR} & \en{Accuracy} & \en{F1 score} & \en{BDR} \\
 \hline
1 & 91.04 & 0.94 & 98.17 & 91.73 & 0.91\\
  \hline
2 & 91.04 & 0.75 & 98.33 & 92.42 & 0.93\\
  \hline
3 & 92.54 & 0.38 & 98.83 & 94.66 & 0.96\\
  \hline
4 & 91.04 & 0.75 & 98.33 & 92.42 & 0.93\\
  \hline
5 & 91.04 & 0.38 & 98.67 & 93.85 & 0.96 \\
 \hline
6 & 80.60 & 0.75 & 97.17 & 86.40 & 0.92\\
 \hline
7 & 83.58 & 1.13 & 97.17 & 86.82 & 0.89\\
 \hline
8 & 91.04 & 0.94 & 98.17 & 91.73 & 0.91\\
 \hline
\end{tabular}
\caption{Αποτελέσματα δοκιμής μικτών τύπων}
\label{tab:exploreclassifiersmix}
\end{table}
\newpage
\section{Εξερεύνηση χρονικής υποδιαίρεσης χρονοσειρών}
Ολοκληρώνοντας την εξερεύνηση των ταξινομητών απαιτείται να γίνει έλεγχος στις χρονικές υποδιαιρέσεις των χρονοσειρών. Για αυτό το σκοπό έγινε δοκιμή του πιο εύστοχου ταξινομητή σε 2.000 καταναλωτές με ποσοστό ρευματοκλοπών 10\% και μόνο απάτες τύπου 1. Στη δοκιμή οι χρονοσειρές διαιρέθηκαν σε ημερήσιες, ωριαίες και ημίωρες μετρήσεις λαμβάνοντας υπόψη όχι μόνο τις μετρικές ευστοχίας, αλλά και τον χρόνο εκτέλεσης της εκπαίδευσης κάθε ταξινομητή. Στον Πίνακα \ref{tab:timedivision} εμφανίζεται όπως αναμενόταν πως όσο αυξάνεται η συχνότητα των μετρήσεων τόσο πιο εύστοχος γίνεται ο ταξινομητής. Παρόλα αυτά ο χρόνος εκτέλεσης της εκπαίδευσης φαίνεται να επηρεάζεται έντονα από διαφορετικές χρονικές υποδιαιρέσεις με την ταξινόμηση με συχνότητα λήξης ανά ημέρα να είναι σημαντικά γρηγορότερη από τις υπόλοιπες, αλλά παρουσιάζει σχετική δυσκολία στην αναγνώριση της απάτης. 

\begin{table}
\centering
\begin{tabular}{ |c||c|c|c|c|c|c|  }
 \hline
 Συχνότητα & \en{DR}  & \en{FPR} & \en{Accuracy} & \en{F1 score} & \en{BDR} & χρόνος εκπαίδευσης \en{(s)}\\
 \hline
μέρες & 76.81 & 0.75 & 96.67 & 84.13 & 0.92 & 0.033682\\
 \hline
ώρες & 95.71 & 0.00 & 99.50 & 97.81 & 1.00& 1.114960\\
  \hline
ημίωρα & 98.18 & 0.55 & 99.33 & 96.43 & 0.95& 2.134732\\
  \hline
\end{tabular}
\caption{Αποτελέσματα δοκιμής χρονικής υποδιαίρεσης}
\label{tab:timedivision}
\end{table}

\section{Θεωρία Μηχανών Διανυσμάτων Υποστήριξης}
Για την ταξινόμηση με μηχανές διανυσμάτων υποστήριξης επιλέχθηκε η βιβλιοθήκη \en{LIBSVM}, η οποία προέρχεται τους ίδιους δημιουργούς της \en{LIBLINEAR}. Σκοπός του \en{SVM} είναι η παραγωγή μοντέλων (βαση των δεδομένων εκπαίδευσης), τα οποία προβλέπουν τα χαρακτηριστικά των δεδομένων δοκιμής βάση μόνο των πληροφοριών που αντλούνται από τις τιμές των δεδομένων.\par
Ξεκινώντας από τα δεδομένα εκπαίδευσης έχουμε ζευγάρια παραδειγμάτων-δυαδικών χαρακτηριστικών $(\mathbf{x}_i,y_i)$,$i=1,...,l$ όπου $\mathbf{x}_i\in\R^n$ και $y\in\{1,-1\}^l$, οι μηχανές διανυσμάτων  υποστήριξης \en{(SVM)} απαιτούν την λύση του παρακάτω προβλήματος βελτιστοποίησης:
\begin{center}
$min_{\mathbf{w},\mathbf{b},\mathbf{\xi}} \frac{1}{2}\mathbf{w}^T\mathbf{w}+C\sum_{i=1}^l\xi_i$\\
δεδομένου $y_i(\mathbf{w}^T\phi(\mathbf{x}_i)+b)\geq 1-\xi_i$,\\
$\xi_i \geq 0$
\end{center}
Εδώ τα διανύσματα εκπαίδευσης $\mathbf{x}_i$, ανάγονται σε μεγαλύτερο (ίσως άπειρο) χώρο διαστάσεων από τη συνάρτηση $\phi$. Τα \en{SVM} βρίσκουν ένα γραμμικά διαχωρίσιμο υπερεπίπεδο με μέγιστο περιθώριο σε αυτό χώρο ανώτερων διαστάσεων. $C>0$ είναι ο παράγοντας που θέτει ποινή στον παράγοντα λάθους (\en{error term}). Επιπροσθέτως, η σχέση $K(\mathbf{x}_i,\mathbf{x}_j)\equiv \phi(\mathbf{x}_i)^T\phi(\mathbf{x}_j)$ ονομάζεται συνάρτηση πυρήνα. Παρόλο που νέοι πυρήνες προτείνονται από ερευνητές, έχουν θεσπιστεί οι ακόλουθοι:
\begin{itemize}
\item Γραμμικός: $K(\mathbf{x}_i,\mathbf{x}_j)= \mathbf{x}_i^T\mathbf{x}_j$.
\item Πολυωνυμικός: $K(\mathbf{x}_i,\mathbf{x}_j)= (\gamma\mathbf{x}_i^T\mathbf{x}_j+r)^d$, $\gamma>0$.
\item \en{RBF}: $K(\mathbf{x}_i,\mathbf{x}_j)= exp(-\gamma\|\mathbf{x}_i-\mathbf{x}_j\|^2)$, $\gamma>0$.
\item Σιγμοειδής: $K(\mathbf{x}_i,\mathbf{x}_j)= tanh(\gamma\mathbf{x}_i^T\mathbf{x}_j +r)$.
\end{itemize}
Εδώ τα $\gamma$, $r$ και $d$ είναι παράμετροι των πυρήνων.
\section{Δοκιμή ταξινόμησης με Μηχανές Διανυσμάτων Υποστήριξης}
\subsection{Δοκιμή χρονοσειρών χωρίς πυρήνα}
\subsubsection{Αποτελέσματα δοκιμής}
\subsection{Δοκιμή χαρακτηριστικών με πυρήνα RBF}
\subsubsection{Αποτελέσματα δοκιμής}
\section{Σχόλια}